{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6f53ac",
   "metadata": {},
   "source": [
    "# Logistische Regression mit Scikit-Learn\n",
    "## Stopword Erkennung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daccf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c1fcd",
   "metadata": {},
   "source": [
    "Der Datensatz **stopword_corpus_mixed.txt** besitzt folgende Spalten, getrennt durch Kommata:\\\n",
    "[0] = word, \\\n",
    "[1] = starts_with_vowel, \\\n",
    "[2] = charlen (Anzahl Buchstaben),\\\n",
    "[3] = logfreq (logarithmierte Frequenz), \\\n",
    "[4] = category \\\n",
    "Die Spalten [2] und [3] sollen als Inputs (X) für den Klassifizierer fungieren, Spalte [4] soll klassifiziert werden (y).\n",
    "\n",
    "Der Datensatz besteht aus 211 Zeilen.\n",
    "Davon sollen die ersten 160 Zeilen für das Training des Klassifizierers verwendet werden\n",
    "und die restlichen 51 Zeilen sollen in einem Testdurchlauf klassifiziert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"stopword_corpus_mixed.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983935c",
   "metadata": {},
   "source": [
    "### Daten einlesen als Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"word\", \"starts_with_vowel\", \"charlen\", \"logfreq\", \"category\"]\n",
    "\n",
    "data = pd.read_csv(filename, header=None, names=col_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d8502",
   "metadata": {},
   "source": [
    "### Features extrahieren\n",
    "Diesmal gibt es für jeden Datenpunkt konkrete Features, die wir verwenden wollen und der Datensatz ist entsprechend bereits aufbereitet. Wir können daher einfach eine Teilmenge der Spalten als Features (die üblicherweise mit `X` benannt werden) deklarieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"charlen\", \"logfreq\"]\n",
    "\n",
    "X = data[feature_cols] # Features\n",
    "y = data.category # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71541f8f",
   "metadata": {},
   "source": [
    "### Daten in Trainings- und Testdaten aufsplitten\n",
    "mit `test_size` (alternativ `train_size`) geben wir an, welcher Anteil der Daten als Testdaten (bzw. Trainingsdaten) verwendet werden soll. Um die absolute Anzahl der Datenpunkte anzugeben, einfach einen Integer-Wert verwenden. Mit `shuffle = True` werden die Datenpunkte zunächst zufällig durcheinandergewürfelt. Damit wir bei jedem Durchgang dasselbe Ergebnis erhalten, muss unbedingt ein `random_state` gesetzt werden (der Wert ist egal!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a23c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=160, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34364e57",
   "metadata": {},
   "source": [
    "### Klassifikator trainieren\n",
    "Wir verwenden hier eine Logistische Regression mit Default-Parametern. Wir setzen nur einen `random_state`, der dafür sorgt, dass wir mit den gleichen Daten auch immer die gleichen Ergebnisse bekommen. Mit der Methode `fit()` wird der Klassifikator trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=16)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5201632",
   "metadata": {},
   "source": [
    "### Klassifikator anwenden\n",
    "Mit `predict()` werden dann die Klassen für die Testdaten vorhergesagt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ad606",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58dc84",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Wir vergleichen nun `y_pred`, also die vorhergesagten Klassen mit `y_test` also den tatsächlichen Klassen für die Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc15191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe736e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfusionsmatrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    \n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifikations-Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82daee7",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gewichte:\", logreg.coef_)\n",
    "print(\"Bias:\", logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e4d9b",
   "metadata": {},
   "source": [
    "Feature [2] = charlen (Anzahl Buchstaben) hat ein negatives Gewicht\n",
    " -> je mehr Buchstaben ein Wort hat, desto mehr geht die Wahrscheinlichkeit zu y = 0 (nonstopword)\\\n",
    " Feature [3] = logfreq (logarithmierte Frequenz) hat ein positives Gewicht\n",
    " -> je häufiger das Wort ist, desto mehr geht die Wahrscheinlichkeit zu y = 1 (stopword)\n",
    "\n",
    " Das deckt sich mit dem gängigen Wissen: Stopwords sind kurze, häufige Wörter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553dbb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
